{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10418433,"sourceType":"datasetVersion","datasetId":6457042},{"sourceId":10418721,"sourceType":"datasetVersion","datasetId":6457059},{"sourceId":10424584,"sourceType":"datasetVersion","datasetId":6461372}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 0. Setup","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport os\n\nuser_secrets = UserSecretsClient()\nos.environ['GITHUB_PAT'] = user_secrets.get_secret(\"GITHUB_PAT\")\nos.environ['ZILLIZ_PASSWORD'] = user_secrets.get_secret(\"ZILLIZ_PASSWORD\")\nos.environ['ZILLIZ_URI'] = user_secrets.get_secret(\"ZILLIZ_URI\")\nos.environ['ZILLIZ_USER'] = user_secrets.get_secret(\"ZILLIZ_USER\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:39:40.240574Z","iopub.execute_input":"2025-01-12T21:39:40.240853Z","iopub.status.idle":"2025-01-12T21:39:40.961025Z","shell.execute_reply.started":"2025-01-12T21:39:40.240831Z","shell.execute_reply":"2025-01-12T21:39:40.960173Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"repo_url = f\"https://{os.getenv('GITHUB_PAT')}@github.com/tmtsmrsl/uconline_poc.git\"\n!git clone -b dev {repo_url}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:39:40.962249Z","iopub.execute_input":"2025-01-12T21:39:40.962551Z","iopub.status.idle":"2025-01-12T21:39:42.008894Z","shell.execute_reply.started":"2025-01-12T21:39:40.962520Z","shell.execute_reply":"2025-01-12T21:39:42.007836Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'uconline_poc'...\nremote: Enumerating objects: 459, done.\u001b[K\nremote: Counting objects: 100% (459/459), done.\u001b[K\nremote: Compressing objects: 100% (247/247), done.\u001b[K\nremote: Total 459 (delta 268), reused 377 (delta 197), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (459/459), 236.29 KiB | 9.84 MiB/s, done.\nResolving deltas: 100% (268/268), done.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%cd /kaggle/working/uconline_poc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:39:42.010766Z","iopub.execute_input":"2025-01-12T21:39:42.011060Z","iopub.status.idle":"2025-01-12T21:39:42.018063Z","shell.execute_reply.started":"2025-01-12T21:39:42.011034Z","shell.execute_reply":"2025-01-12T21:39:42.017248Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/uconline_poc\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!cp -r /kaggle/input/artifact /kaggle/working/uconline_poc/artifact","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:39:42.019156Z","iopub.execute_input":"2025-01-12T21:39:42.019385Z","iopub.status.idle":"2025-01-12T21:39:42.427300Z","shell.execute_reply.started":"2025-01-12T21:39:42.019366Z","shell.execute_reply":"2025-01-12T21:39:42.426374Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pip install -q -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:39:42.428284Z","iopub.execute_input":"2025-01-12T21:39:42.428614Z","iopub.status.idle":"2025-01-12T21:42:58.863342Z","shell.execute_reply.started":"2025-01-12T21:39:42.428583Z","shell.execute_reply":"2025-01-12T21:42:58.862368Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.7/169.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.8/161.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.3/455.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m979.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.4/326.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.9/347.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.8/118.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.29.3 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ndistributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\nfastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.5.1 which is incompatible.\ngcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.3.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\ngoogle-cloud-bigtable 2.26.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\ngoogle-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.2 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.29.3 which is incompatible.\ntensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\ntensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.29.3 which is incompatible.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\ntorchvision 0.19.1+cu121 requires torch==2.4.1, but you have torch 2.5.1 which is incompatible.\nypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 23.2.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport joblib\nimport json \nimport re\nimport torch\nfrom dotenv import load_dotenv\n\nfrom pymilvus.model.hybrid import BGEM3EmbeddingFunction\nfrom pymilvus.model.sparse.bm25 import BM25EmbeddingFunction\nfrom pymilvus import (\n    FieldSchema,\n    CollectionSchema,\n    DataType,\n    Collection,\n    connections,\n)\n\nfrom ETL.ContentProcessor import ContentDocProcessor\nfrom ETL.TranscriptProcessor import TranscriptDocProcessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:42:58.864304Z","iopub.execute_input":"2025-01-12T21:42:58.864633Z","iopub.status.idle":"2025-01-12T21:43:12.015229Z","shell.execute_reply.started":"2025-01-12T21:42:58.864602Z","shell.execute_reply":"2025-01-12T21:43:12.014527Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 1. Scrape the HTML content and video transcripts\nCheck the README.md file for the instructions on how to scrape the HTML content and video transcripts.","metadata":{}},{"cell_type":"markdown","source":"## 2. Convert the HTML content and video transcripts to documents","metadata":{}},{"cell_type":"code","source":"# This it the chunking option for the text processing.\nCHUNK_TOKEN_SIZE = 500\nCHUNK_TOKEN_OVERLAP = 50\nTEXT_SPLITTER_OPTIONS = {\"chunk_token_size\": CHUNK_TOKEN_SIZE, \"chunk_token_overlap\": CHUNK_TOKEN_OVERLAP}\n\n# We want the output as Langchain Document\nRETURN_DICT = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:43:12.015981Z","iopub.execute_input":"2025-01-12T21:43:12.016519Z","iopub.status.idle":"2025-01-12T21:43:12.020401Z","shell.execute_reply.started":"2025-01-12T21:43:12.016485Z","shell.execute_reply":"2025-01-12T21:43:12.019598Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"HTML_CONTENT_DIR = \"artifact/emgt605/html_content\"\n\n# The CSS elements to exclude when extracting text from the HTML content\nEXCLUDED_ELEMENTS_CSS='div.quiz-card__feedback, div.block-knowledge__retake-container, a, iframe'\n\n# Traverse the JSON_DIR and process all the JSON files \nhtml_content_docs = []\njson_files = [f for f in os.listdir(HTML_CONTENT_DIR) if f.endswith('.json')]\ncontent_doc_processor = ContentDocProcessor(text_splitter_options=TEXT_SPLITTER_OPTIONS, excluded_elements_css=EXCLUDED_ELEMENTS_CSS, return_dict=RETURN_DICT)\n\nfor json_file in json_files:\n    json_path = os.path.join(HTML_CONTENT_DIR, json_file)\n    docs = content_doc_processor.run(json_path)\n    for doc in docs:\n        doc.metadata['content_type'] = 'html_content'\n    html_content_docs.extend(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:43:12.022628Z","iopub.execute_input":"2025-01-12T21:43:12.022866Z","iopub.status.idle":"2025-01-12T21:43:21.618925Z","shell.execute_reply.started":"2025-01-12T21:43:12.022845Z","shell.execute_reply":"2025-01-12T21:43:21.618180Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"b. Load the transcript files and metadata from the `transcripts` directory (output directory of `TranscriptScraper.py`) and convert the video transcripts into documents.","metadata":{}},{"cell_type":"code","source":"TRANSCRIPT_DIR = \"artifact/emgt605/transcripts\"\n\n# Traverse the TRANSCRIPT_DIR and process all the transcript files\ntranscript_docs = []\nmodule_dirs = os.listdir(TRANSCRIPT_DIR)\ntranscript_doc_processor = TranscriptDocProcessor(text_splitter_options=TEXT_SPLITTER_OPTIONS, return_dict=RETURN_DICT)\n\nfor module_dir in module_dirs:\n    module_path = os.path.join(TRANSCRIPT_DIR, module_dir)\n    docs = transcript_doc_processor.process_module_transcripts(module_path)\n    for doc in docs:\n        doc.metadata['content_type'] = 'video_transcript'\n    transcript_docs.extend(docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:43:21.619990Z","iopub.execute_input":"2025-01-12T21:43:21.620259Z","iopub.status.idle":"2025-01-12T21:43:33.490702Z","shell.execute_reply.started":"2025-01-12T21:43:21.620235Z","shell.execute_reply":"2025-01-12T21:43:33.490036Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c069a3422c06403da6127e061e908e2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4cc90f7f3734b0d84254bf0e7231346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/447 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba32733091b94b85a32f709d8b3b1d32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20033b55721d46f5a2e06f50b124b430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e066fbdbbe44a30b20472b39576fa5c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n  warnings.warn(\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"combined_docs = html_content_docs + transcript_docs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:43:33.491502Z","iopub.execute_input":"2025-01-12T21:43:33.491815Z","iopub.status.idle":"2025-01-12T21:43:33.495587Z","shell.execute_reply.started":"2025-01-12T21:43:33.491784Z","shell.execute_reply":"2025-01-12T21:43:33.494701Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 3. Document Embeddings and Vector DB Loading","metadata":{}},{"cell_type":"markdown","source":"Initialize the dense embedding model. Note that using GPU is highly recommended for this task as it will be much faster.","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndense_embeddings = BGEM3EmbeddingFunction(use_fp16=False, device=DEVICE, return_dense=True, return_sparse=False)\ndense_dim = dense_embeddings.dim['dense']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:43:33.496411Z","iopub.execute_input":"2025-01-12T21:43:33.496701Z","iopub.status.idle":"2025-01-12T21:44:31.756976Z","shell.execute_reply.started":"2025-01-12T21:43:33.496675Z","shell.execute_reply":"2025-01-12T21:44:31.756334Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54e0b71827ad43df94062a8544b0e49a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"310a1d7bd37b429c991d71bc4a4dd2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e7470c472647a782bdc5cee9e3ba25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef413e25847b4b63bd2c25cc57e99008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3980f4eb3ef43cbab334c63e59b5a17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"colbert_linear.pt:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2a0a74637fc4dd1b1120280ab19f1ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57090593da9b49949129f03808e67128"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a06979abb4814df38e392a097b8f2d27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27a18b646d4046649fcf81cac188729e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imgs/.DS_Store:   0%|          | 0.00/6.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3efde9303a944a0a9e1bc72ddc94a889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imgs/mkqa.jpg:   0%|          | 0.00/608k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a06df8e2e01240b692e2fddab15852a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imgs/long.jpg:   0%|          | 0.00/485k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e30581dfe3ec4be8a2d04b7e8e168945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imgs/others.webp:   0%|          | 0.00/21.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38c66071c786462b8a951f4b24e019fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imgs/miracl.jpg:   0%|          | 0.00/576k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7b647c466f14b05bbfad1825e40430b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"imgs/nqa.jpg:   0%|          | 0.00/158k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd666bb2af824ba1aecf8d39687f6b6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"888ce7b493e64b06bd4cdeed06029ee6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"long.jpg:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ee95a4f5c742fc8eac7ebe94ecb33b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/Constant_7_attr__value:   0%|          | 0.00/65.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0992ed6a1bfa41198b793cb698f34c26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.onnx_data:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e1c725502743ee811d5896f7266c45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8599dd01d3d24efba9b31df5dcc15ef8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.onnx:   0%|          | 0.00/725k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3241b082d017406ca4f9270033b302ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f19b9aa035f4648b7e8a8db12f7009d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"onnx/tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1df5ae6543d4dbda1707b3b73dda805"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59fdbecd75f1445b888441995d24d3f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sparse_linear.pt:   0%|          | 0.00/3.52k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d2338345b7451eb34db2a23a4fa438"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7d919974ae44488ae41183734dc600f"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"Initialize the BM25 sparse embeddings and save them to disk. Notice that we fit the BM25 embedding model to the original text to preserve the original distibution of the word count.","metadata":{}},{"cell_type":"code","source":"SPARSE_EMBEDDINGS_PATH = \"artifact/emgt605/sparse_embeddings_v2.joblib\"\n\noriginal_texts = [doc.page_content for doc in combined_docs]\nsparse_embeddings = BM25EmbeddingFunction(corpus=original_texts)\n\nfolder_path = os.path.dirname(SPARSE_EMBEDDINGS_PATH)\nos.makedirs(folder_path, exist_ok=True)\njoblib.dump(sparse_embeddings, SPARSE_EMBEDDINGS_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:44:31.757839Z","iopub.execute_input":"2025-01-12T21:44:31.758642Z","iopub.status.idle":"2025-01-12T21:44:33.618439Z","shell.execute_reply.started":"2025-01-12T21:44:31.758607Z","shell.execute_reply":"2025-01-12T21:44:33.617572Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['artifact/emgt605/sparse_embeddings_v2.joblib']"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"We will use the text with contextual header for both the sparse and dense embedding. The added context will improve the representation of both embeddings types. I don't modify the text directly in the document as it would complicate the indexing and deduplication step during the post-retrieval step.","metadata":{}},{"cell_type":"code","source":"def generate_contextual_header(doc):\n    source_metadata = doc.metadata\n    # if source_metadata['content_type'] == 'video_transcript':\n    #     # Replace newlines with a single space and truncate to 1000 characters\n    #     video_desc = re.sub(r'\\n+', ' ', source_metadata['video_desc'][:1000])\n    #     return f\"Below are transcript snippet from video with a description of: {video_desc.strip()}:\\n\"\n        \n    # elif source_metadata['content_type'] == 'html_content':\n    return (\n        f\"Below are content snippet of: {source_metadata['module_title']} - \"\n        f\"{source_metadata['subsection']}: {source_metadata['submodule_title']}:\"\n    )\n    # return context + \"\\n\" + doc.page_content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:49:07.975274Z","iopub.execute_input":"2025-01-12T21:49:07.975627Z","iopub.status.idle":"2025-01-12T21:49:07.979943Z","shell.execute_reply.started":"2025-01-12T21:49:07.975604Z","shell.execute_reply":"2025-01-12T21:49:07.979189Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"Create the dense and sparse vectors for the documents.","metadata":{}},{"cell_type":"code","source":"contextual_texts = []\nfor doc in combined_docs:\n    doc.metadata['contextual_header'] = generate_contextual_header(doc)\n    contextual_texts.append(f\"{doc.metadata['contextual_header']}\\n{doc.page_content}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:50:17.017984Z","iopub.execute_input":"2025-01-12T21:50:17.018356Z","iopub.status.idle":"2025-01-12T21:50:17.023797Z","shell.execute_reply.started":"2025-01-12T21:50:17.018327Z","shell.execute_reply":"2025-01-12T21:50:17.022889Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"sparse_vectors = sparse_embeddings.encode_documents(contextual_texts)\ndense_vectors = dense_embeddings.encode_documents(contextual_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:51:09.895242Z","iopub.execute_input":"2025-01-12T21:51:09.895572Z","iopub.status.idle":"2025-01-12T21:51:43.184686Z","shell.execute_reply.started":"2025-01-12T21:51:09.895546Z","shell.execute_reply":"2025-01-12T21:51:43.183807Z"}},"outputs":[{"name":"stderr","text":"pre tokenize: 100%|██████████| 21/21 [00:00<00:00, 60.28it/s]\nYou're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\nInference Embeddings: 100%|██████████| 21/21 [00:28<00:00,  1.37s/it]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def convert_doc_to_dict(doc):\n    temp_doc = doc.dict()\n    temp_doc['index_metadata'] = temp_doc['metadata'].pop('index_metadata', [])\n    temp_doc['text'] = temp_doc.pop('page_content')\n    temp_doc.pop('id', None)\n    temp_doc.pop('type', None)\n    \n    return temp_doc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:51:43.185929Z","iopub.execute_input":"2025-01-12T21:51:43.186289Z","iopub.status.idle":"2025-01-12T21:51:43.190441Z","shell.execute_reply.started":"2025-01-12T21:51:43.186257Z","shell.execute_reply":"2025-01-12T21:51:43.189656Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"combined_dict = [convert_doc_to_dict(doc) for doc in combined_docs]\nfor i, doc in enumerate(combined_dict):\n    doc['sparse_vector'] = sparse_vectors[[i], :]\n    doc['dense_vector'] = dense_vectors['dense'][i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:51:43.191946Z","iopub.execute_input":"2025-01-12T21:51:43.192236Z","iopub.status.idle":"2025-01-12T21:51:43.240961Z","shell.execute_reply.started":"2025-01-12T21:51:43.192214Z","shell.execute_reply":"2025-01-12T21:51:43.240175Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-31-238f70520eac>:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n  temp_doc = doc.dict()\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"Make a connection to the Zilliz vector database and load the embeddings into the vector database.","metadata":{}},{"cell_type":"code","source":"# This is the parameter to connect to the Zilliz vector database\nZILLIZ_URI = os.getenv(\"ZILLIZ_URI\")\nZILLIZ_USER = os.getenv(\"ZILLIZ_USER\")\nZILLIZ_PASSWORD = os.getenv(\"ZILLIZ_PASSWORD\")\nCOLLECTION_NAME = \"emgt_605_video_bge_bm25_500_50\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:53:12.416320Z","iopub.execute_input":"2025-01-12T21:53:12.416621Z","iopub.status.idle":"2025-01-12T21:53:12.420497Z","shell.execute_reply.started":"2025-01-12T21:53:12.416599Z","shell.execute_reply":"2025-01-12T21:53:12.419671Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"connections.connect(user=ZILLIZ_USER, password=ZILLIZ_PASSWORD, uri=ZILLIZ_URI)\n\nfields = [\n    FieldSchema(\n        name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n    ),\n    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=8192),\n    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n    FieldSchema(name=\"metadata\", dtype=DataType.JSON),\n    FieldSchema(name=\"index_metadata\", dtype=DataType.JSON)\n    # FieldSchema(name=\"module_title\", dtype=DataType.VARCHAR, max_length=500),\n    # FieldSchema(name=\"subsection\", dtype=DataType.VARCHAR, max_length=500),\n    # FieldSchema(name=\"submodule_title\", dtype=DataType.VARCHAR, max_length=500),\n    # FieldSchema(name=\"submodule_url\", dtype=DataType.VARCHAR, max_length=500),\n    # FieldSchema(name=\"content_type\", dtype=DataType.VARCHAR, max_length=500),\n]\n\nschema = CollectionSchema(fields, \n                          \"Dense (BGE-M3) and Sparse (BM25) Embeddings for EMGT605 Course Content\", \n                          enable_dynamic_field=True)\ncol = Collection(COLLECTION_NAME, schema)\n\nsparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\ndense_index = {\"index_type\": \"FLAT\", \"metric_type\": \"COSINE\"}\ncol.create_index(\"sparse_vector\", sparse_index)\ncol.create_index(\"dense_vector\", dense_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:53:31.947373Z","iopub.execute_input":"2025-01-12T21:53:31.947645Z","iopub.status.idle":"2025-01-12T21:53:33.474759Z","shell.execute_reply.started":"2025-01-12T21:53:31.947626Z","shell.execute_reply":"2025-01-12T21:53:33.474029Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Status(code=0, message=)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"col.insert(combined_dict)\ncol.load()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:53:43.873176Z","iopub.execute_input":"2025-01-12T21:53:43.873472Z","iopub.status.idle":"2025-01-12T21:53:44.851482Z","shell.execute_reply.started":"2025-01-12T21:53:43.873442Z","shell.execute_reply":"2025-01-12T21:53:44.850517Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"## 4. Retrieval Testing","metadata":{}},{"cell_type":"markdown","source":"Check if the documents has been loaded correctly into the vector database. Note that we will initialize the retriever using the pymilvus SDK instead of Langchain because currently Langchain does not support the BM25 retriever.","metadata":{}},{"cell_type":"code","source":"connections.connect(user=ZILLIZ_USER, password=ZILLIZ_PASSWORD, uri=ZILLIZ_URI)\ncol = Collection(COLLECTION_NAME)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:54:42.095153Z","iopub.execute_input":"2025-01-12T21:54:42.095453Z","iopub.status.idle":"2025-01-12T21:54:42.203621Z","shell.execute_reply.started":"2025-01-12T21:54:42.095431Z","shell.execute_reply":"2025-01-12T21:54:42.202893Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"output_fields = [\n            \"pk\",\n            \"metadata\",\n            \"index_metadata\",\n            \"text\"   \n        ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:54:42.940309Z","iopub.execute_input":"2025-01-12T21:54:42.940571Z","iopub.status.idle":"2025-01-12T21:54:42.944083Z","shell.execute_reply.started":"2025-01-12T21:54:42.940552Z","shell.execute_reply":"2025-01-12T21:54:42.943287Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"query = \"What are some goals of UN SDG?\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:57:57.960560Z","iopub.execute_input":"2025-01-12T21:57:57.960882Z","iopub.status.idle":"2025-01-12T21:57:57.964465Z","shell.execute_reply.started":"2025-01-12T21:57:57.960855Z","shell.execute_reply":"2025-01-12T21:57:57.963575Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"dense_query = dense_embeddings.encode_queries([query])['dense']\ndense_results = col.search(dense_query, \n                           anns_field=\"dense_vector\", \n                           limit=5, param={\"metric_type\": \"COSINE\"}, \n                           output_fields=output_fields,\n                          # expr='metadata[\"content_type\"]==\"video_transcript\"'\n                          )\n# print(dense_results[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:57:58.373452Z","iopub.execute_input":"2025-01-12T21:57:58.373660Z","iopub.status.idle":"2025-01-12T21:57:58.453845Z","shell.execute_reply.started":"2025-01-12T21:57:58.373641Z","shell.execute_reply":"2025-01-12T21:57:58.453054Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"sparse_query = sparse_embeddings.encode_queries([query])\nsparse_results = col.search(sparse_query,\n                            anns_field=\"sparse_vector\", \n                            limit=5, param={\"metric_type\": \"IP\"}, \n                            output_fields=output_fields,\n                           # expr='metadata[\"content_type\"]==\"html_content\"'\n                           )\n# print(sparse_results[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T21:57:58.870065Z","iopub.execute_input":"2025-01-12T21:57:58.870319Z","iopub.status.idle":"2025-01-12T21:57:58.887905Z","shell.execute_reply.started":"2025-01-12T21:57:58.870299Z","shell.execute_reply":"2025-01-12T21:57:58.887361Z"}},"outputs":[],"execution_count":78}]}