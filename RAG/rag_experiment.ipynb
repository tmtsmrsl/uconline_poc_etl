{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_milvus.vectorstores import Milvus\n",
    "from langgraph.graph import START, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from thefuzz import fuzz, process\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize GPU to load and infer the embedding model if available \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# We will use bge-m3 model to generate the dense vectors/ embeddings\n",
    "EMBEDDING_MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
    "\n",
    "# This is the parameter to connect to the Zilliz vector database\n",
    "ZILLIZ_URI = os.getenv(\"ZILLIZ_URI\")\n",
    "ZILLIZ_USER = os.getenv(\"ZILLIZ_USER\")\n",
    "ZILLIZ_PASSWORD = os.getenv(\"ZILLIZ_PASSWORD\")\n",
    "COLLECTION_NAME = \"emgt_605_jina\"\n",
    "\n",
    "# Enable the tracing feature of Langsmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_retriever(embedding_function, zilliz_uri, zilliz_user, zilliz_password, collection_name):\n",
    "    vector_store = Milvus(\n",
    "    embedding_function=[embedding_function],\n",
    "    connection_args={\n",
    "        \"uri\": zilliz_uri,\n",
    "        \"user\": zilliz_user,\n",
    "        \"password\": zilliz_password,\n",
    "        \"secure\": True},\n",
    "    collection_name=collection_name)\n",
    "    \n",
    "    return vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marselo\\OneDrive\\Documents\\GitHub\\uconline_poc\\proj.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {\"device\": DEVICE, \"trust_remote_code\":True}\n",
    "dense_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the vector database retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = load_retriever(dense_embeddings, ZILLIZ_URI, ZILLIZ_USER, \n",
    "                        ZILLIZ_PASSWORD, COLLECTION_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(api_key=GROQ_API_KEY, model=\"llama-3.3-70b-versatile\", temperature=0, max_retries=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastembed import LateInteractionTextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answerai_colbert = LateInteractionTextEmbedding(model_name=\"answerdotai/answerai-colbert-small-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def compute_relevance_scores(query_embedding: np.array, document_embeddings: np.array, k: int):\n",
    "#     \"\"\"\n",
    "#     Compute relevance scores for top-k documents given a query.\n",
    "\n",
    "#     :param query_embedding: Numpy array representing the query embedding, shape: [num_query_terms, embedding_dim]\n",
    "#     :param document_embeddings: Numpy array representing embeddings for documents, shape: [num_documents, max_doc_length, embedding_dim]\n",
    "#     :param k: Number of top documents to return\n",
    "#     :return: Indices of the top-k documents based on their relevance scores\n",
    "#     \"\"\"\n",
    "#     # Compute batch dot-product of query_embedding and document_embeddings\n",
    "#     # Resulting shape: [num_documents, num_query_terms, max_doc_length]\n",
    "#     scores = np.matmul(query_embedding, document_embeddings.transpose(0, 2, 1))\n",
    "\n",
    "#     # Apply max-pooling across document terms (axis=2) to find the max similarity per query term\n",
    "#     # Shape after max-pool: [num_documents, num_query_terms]\n",
    "#     max_scores_per_query_term = np.max(scores, axis=2)\n",
    "\n",
    "#     # Sum the scores across query terms to get the total score for each document\n",
    "#     # Shape after sum: [num_documents]\n",
    "#     total_scores = np.sum(max_scores_per_query_term, axis=1)\n",
    "\n",
    "#     # Sort the documents based on their total scores and get the indices of the top-k documents\n",
    "#     sorted_indices = np.argsort(total_scores)[::-1][:k]\n",
    "\n",
    "#     return sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rerank_docs_query(model, docs, query):\n",
    "#     document_embeddings = list(model.embed(docs))\n",
    "#     query_embeddings = list(model.embed([query]))\n",
    "    \n",
    "#     sorted_indices = compute_relevance_scores(\n",
    "#     np.array(query_embeddings[0]), np.array(document_embeddings), k=3)\n",
    "#     return [docs[i] for i in sorted_indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt and Flow Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test several patterns for the RAG system. Sources are defined as the context retrieved from the vector database while quotes are a specific span of the source that is used to formulate the final answer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CitationProcessor class will be used to check the match between the sources and quotes, and generate the citation for the final answer which will redirect to the lesson blocks of the submodule page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitationProcessor:\n",
    "    def __init__(self, context, citations):\n",
    "        \"\"\"\n",
    "        Initialize the CitationProcessor with the result object.\n",
    "        \"\"\"\n",
    "        self.context = context\n",
    "        self.citations = citations\n",
    "        self.detailed_sources = []\n",
    "        self.unique_final_urls = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _search_substring_match(paragraph, substring, threshold=90):\n",
    "        \"\"\"\n",
    "        Search for the best match of a substring in a paragraph using fuzzy matching.\n",
    "        Returns the best match, its score, and its start and end character indices in the paragraph.\n",
    "        \"\"\"\n",
    "        # Find the best match using a sliding window and process.extractOne\n",
    "        substring_length = len(substring)\n",
    "        sliding_para_windows = (paragraph[i:i + substring_length] for i in range(len(paragraph) - substring_length + 1))\n",
    "        best_match, score = process.extractOne(substring, sliding_para_windows, scorer=fuzz.partial_ratio)\n",
    "\n",
    "        # If the score meets the threshold, find start and end indices\n",
    "        if score >= threshold:\n",
    "            start_index = paragraph.find(best_match)\n",
    "            end_index = start_index + len(best_match)\n",
    "            return best_match, score, start_index, end_index\n",
    "        else:\n",
    "            return None, score, None, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def _extract_data_block_ids(data_block_ranges, start_index, end_index):\n",
    "        \"\"\"\n",
    "        Extract the IDs of the data blocks that overlap with the provided range.\n",
    "        \"\"\"\n",
    "        # List to hold the IDs of matching data blocks\n",
    "        overlapping_ids = []\n",
    "\n",
    "        # Iterate through each data block in the ranges\n",
    "        for data_block_id, range_values in data_block_ranges.items():\n",
    "            # Get the start and end values of the current data block\n",
    "            block_start = range_values['char_start']\n",
    "            block_end = range_values['char_end']\n",
    "            \n",
    "            # Check if the provided range overlaps with the current data block\n",
    "            if start_index <= block_end and end_index >= block_start:\n",
    "                overlapping_ids.append(data_block_id)\n",
    "        \n",
    "        return overlapping_ids  \n",
    "    \n",
    "    def _process_citation(self, citation):\n",
    "        \"\"\"\n",
    "        Process a single citation to extract detailed source information.\n",
    "        \"\"\"\n",
    "        context = self.context[citation.source_id]\n",
    "        prefix, page_content = context.page_content.split(\"\\n\\n\", 1)\n",
    "        \n",
    "        best_match, score, start_index, end_index = self._search_substring_match(page_content, citation.quote)\n",
    "        \n",
    "        if start_index and end_index:\n",
    "            adjusted_start_index = context.metadata['start_index'] + start_index\n",
    "            adjusted_end_index = context.metadata['start_index'] + end_index\n",
    "            data_block_ids = self._extract_data_block_ids(context.metadata['data_block_ranges'], adjusted_start_index, adjusted_end_index)\n",
    "        else:\n",
    "            data_block_ids = []\n",
    "            \n",
    "        return {\"submodule_url\": context.metadata['submodule_url'], \"data_block_ids\": data_block_ids,\n",
    "                \"best_match\": best_match, \"score\": score}\n",
    "    \n",
    "    @staticmethod\n",
    "    def _generate_urls(submodule_url, data_block_ids):\n",
    "        \"\"\"Generate the final URLs by combining the submodule URL with the data blocks.\"\"\"\n",
    "        final_urls = []\n",
    "\n",
    "        for data_block_id in set(data_block_ids):\n",
    "            final_urls.append(submodule_url + f\"/block/{data_block_id}\")\n",
    "            \n",
    "        return final_urls\n",
    "            \n",
    "    def _add_unique_final_urls(self, final_urls):\n",
    "        \"\"\"\n",
    "        Add final URLs to the unique_final_urls list if they don't already exist.\n",
    "        \"\"\"\n",
    "        for final_url in final_urls:\n",
    "            if final_url not in self.unique_final_urls:\n",
    "                self.unique_final_urls.append(final_url)\n",
    "    \n",
    "    def process_citations(self):\n",
    "        \"\"\"\n",
    "        Process all citations in the result to extract detailed sources and final unique URLs.\n",
    "        \"\"\"\n",
    "        for citation in self.citations:\n",
    "            detailed_source = self._process_citation(citation)\n",
    "            if detailed_source:\n",
    "                final_urls = self._generate_urls(detailed_source['submodule_url'], detailed_source['data_block_ids'])\n",
    "                self._add_unique_final_urls(final_urls)\n",
    "                detailed_source['final_url_ids'] = [self.unique_final_urls.index(final_url) for final_url in final_urls]\n",
    "                self.detailed_sources.append(detailed_source)\n",
    "        \n",
    "        return {\"detailed_sources\": self.detailed_sources, \"final_urls_dict\": {i: url for i, url in enumerate(self.unique_final_urls)}}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern 1: Answer with list of quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You're a helpful personalized tutor for Sustainability Systems in Engineering. Given a user question and some course contents, answer the question and justify your answer by providing verbatim citations from the course contents. If none of the course content answer the question, just say: \"Sorry, I can't find any relevant course content related to your question.\".\n",
      "\n",
      "Here are the course contents:\n",
      "\u001b[33;1m\u001b[1;3m{sources}\u001b[0m\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "COURSE_NAME = \"Sustainability Systems in Engineering\"\n",
    "\n",
    "generate_system_prompt = f\"\"\"You're a helpful personalized tutor for {COURSE_NAME}. Given a user question and some course contents, answer the question and justify your answer by providing verbatim citations from the course contents. If none of the course content answer the question, just say: \"Sorry, I can't find any relevant course content related to your question.\".\n",
    "\n",
    "Here are the course contents:\n",
    "{{sources}}\"\"\"\n",
    "\n",
    "generate_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", generate_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "generate_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_sources_with_id(sources: List[Document]) -> str:\n",
    "    formatted = [\n",
    "        f\"SOURCE ID: {i}\\nContent: {doc.page_content}\"\n",
    "        for i, doc in enumerate(sources)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n---\\n\".join(formatted)\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    source_id: int = Field(\n",
    "        ...,\n",
    "        description=\"The integer ID of a SPECIFIC source which justifies the answer.\",\n",
    "    )\n",
    "    quote: str = Field(\n",
    "        ...,\n",
    "        description=\"The VERBATIM quote from the specified source that justifies the answer.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class QuotedAnswer(BaseModel):\n",
    "    \"\"\"Answer the user question based only on the given sources, and cite the sources used.\"\"\"\n",
    "\n",
    "    answer: str = Field(\n",
    "        ...,\n",
    "        description=\"The answer to the user question, which is based only on the given sources.\",\n",
    "    )\n",
    "    citations: List[Citation] = Field(\n",
    "        ..., description=\"Citations from the given sources that justify the answer.\"\n",
    "    )\n",
    "    \n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: QuotedAnswer\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retriever.search_kwargs = {\"k\": 3}\n",
    "    retrieved_sources = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_sources}\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    formatted_sources = format_sources_with_id(state[\"context\"])\n",
    "    messages = generate_prompt.invoke({\"question\": state[\"question\"], \"sources\": formatted_sources})\n",
    "    structured_llm = llm.with_structured_output(QuotedAnswer)\n",
    "    response = structured_llm.invoke(messages)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate_answer])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_final_answer(result) -> str:\n",
    "    final_answer = result['answer'].answer\n",
    "    citations = result['answer'].citations\n",
    "    context = result['context']\n",
    "\n",
    "    # Process citations\n",
    "    citation_processor = CitationProcessor(citations=citations, context=context)\n",
    "    processed_citations = citation_processor.process_citations()\n",
    "\n",
    "    # Format the sources\n",
    "    formatted_sources = \"\\n\".join(f\"{idx}: {url}\" for idx, url in processed_citations['final_urls_dict'].items())\n",
    "\n",
    "    return final_answer, formatted_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"What are different ways to calculate GDP? Please explain them as well.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuotedAnswer(answer='There are three different ways to calculate GDP: the production-based method, the expenditure-based method, and the income-based method. The production-based method calculates GDP by measuring the gross value added from production, which means the total value of goods and services produced minus the cost of inputs used in production to avoid double-counting. The expenditure-based method calculates GDP by looking at what is spent on the acquisition of final products and services within a specific time. The income-based method calculates GDP by adding up all the income earned by households in a year, including wages, rent, and interest.', citations=[Citation(source_id=1, quote='The production-based method calculates GDP by measuring the gross value added from production.'), Citation(source_id=1, quote='The expenditure-based method calculates GDP by looking at what is spent on the acquisition of final products and services within a specific time.'), Citation(source_id=0, quote='The income-based method calculates GDP by adding up all the income earned by households in a year, including: Wages, Rent, Interest')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are three different ways to calculate GDP: the production-based method, the expenditure-based method, and the income-based method. The production-based method calculates GDP by measuring the gross value added from production, which means the total value of goods and services produced minus the cost of inputs used in production to avoid double-counting. The expenditure-based method calculates GDP by looking at what is spent on the acquisition of final products and services within a specific time. The income-based method calculates GDP by adding up all the income earned by households in a year, including wages, rent, and interest.\n",
      "0: https://rise.articulate.com/share/x4kLM8ubXkKXbaSIIYxdg2lUAat8jkZA#/lessons/yDY_9938GpffmDkf3gJF4au8EIJejfRW/block/clh5bei5k000n3n6u58395476\n"
     ]
    }
   ],
   "source": [
    "final_answer, formatted_sources = process_final_answer(result)\n",
    "print(final_answer)\n",
    "print(formatted_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"In NZ what gases emission should be reported?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuotedAnswer(answer='In New Zealand, the following greenhouse gases emissions should be reported: Carbon dioxide (CO2), Methane (CH4), Nitrous oxide (N2O), Hydrofluorocarbons (HFCs), Perfluorocarbons (PFCs), Sulphur hexafluoride (SF6), and Nitrogen trifluoride (NF3).', citations=[Citation(source_id=0, quote='The greenhouse gases that are required for reporting are:'), Citation(source_id=0, quote='* Carbon dioxide (CO2). * Methane (CH4). * Nitrous oxide (N2O). * Hydrofluorocarbons (HFCs). * Perfluorocarbons (PFCs). * Sulphur hexafluoride (SF6). * Nitrogen trifluoride (NF3).')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In New Zealand, the following greenhouse gases emissions should be reported: Carbon dioxide (CO2), Methane (CH4), Nitrous oxide (N2O), Hydrofluorocarbons (HFCs), Perfluorocarbons (PFCs), Sulphur hexafluoride (SF6), and Nitrogen trifluoride (NF3).\n",
      "0: https://rise.articulate.com/share/-45lAOPCrNAZuyFOPHNQPqUXd32Lb236#/lessons/7s54CktDdO1NbrUpN33xHUEzwVFHQ08w/block/cli7znhds009b3n6op40lj1b3\n",
      "1: https://rise.articulate.com/share/-45lAOPCrNAZuyFOPHNQPqUXd32Lb236#/lessons/7s54CktDdO1NbrUpN33xHUEzwVFHQ08w/block/cli7znw7h009j3n6o9z62z84g\n"
     ]
    }
   ],
   "source": [
    "final_answer, formatted_sources = process_final_answer(result)\n",
    "print(final_answer)\n",
    "print(formatted_sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90eff49fb3e24a038f7bb52d841221e01206cd547d9b592876ffc0cc6e591a8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
