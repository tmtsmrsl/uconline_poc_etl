{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marselo\\OneDrive\\Documents\\GitHub\\uconline_poc\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain-community azure-search-documents==11.6.0b8 azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marselo\\OneDrive\\Documents\\GitHub\\uconline_poc\\env.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, \n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    CorsOptions,\n",
    "    ComplexField,\n",
    "    SemanticSearch,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration, \n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField, \n",
    "    SemanticPrioritizedFields\n",
    "    \n",
    ")\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from ETL.ContentProcessor import ContentDocProcessor\n",
    "from ETL.TranscriptProcessor import TranscriptDocProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_KEY = os.getenv(\"AZURE_SEARCH_KEY\")\n",
    "MODEL = \"text-embedding-3-large\"\n",
    "INDEX_NAME = \"emgt605_v3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scrape the HTML content and video transcripts\n",
    "Check the README.md file for the instructions on how to scrape the HTML content and video transcripts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert the HTML content and video transcripts to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This it the chunking option for the text processing.\n",
    "CHUNK_TOKEN_SIZE = 500\n",
    "CHUNK_TOKEN_OVERLAP = 50\n",
    "TEXT_SPLITTER_OPTIONS = {\"chunk_token_size\": CHUNK_TOKEN_SIZE, \"chunk_token_overlap\": CHUNK_TOKEN_OVERLAP}\n",
    "\n",
    "# We want the output as Langchain Document\n",
    "RETURN_DICT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_CONTENT_DIR = \"artifact/emgt605/html_content\"\n",
    "\n",
    "# The CSS elements to exclude when extracting text from the HTML content\n",
    "EXCLUDED_ELEMENTS_CSS='div.quiz-card__feedback, div.block-knowledge__retake-container, a, iframe'\n",
    "\n",
    "# Traverse the JSON_DIR and process all the JSON files \n",
    "html_content_docs = []\n",
    "json_files = [f for f in os.listdir(HTML_CONTENT_DIR) if f.endswith('.json')]\n",
    "content_doc_processor = ContentDocProcessor(text_splitter_options=TEXT_SPLITTER_OPTIONS, excluded_elements_css=EXCLUDED_ELEMENTS_CSS, return_dict=RETURN_DICT)\n",
    "\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(HTML_CONTENT_DIR, json_file)\n",
    "    docs = content_doc_processor.run(json_path)\n",
    "    for doc in docs:\n",
    "        doc.metadata['content_type'] = 'html_content'\n",
    "    html_content_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marselo\\OneDrive\\Documents\\GitHub\\uconline_poc\\env.venv\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSCRIPT_DIR = \"artifact/emgt605/transcripts\"\n",
    "\n",
    "# Traverse the TRANSCRIPT_DIR and process all the transcript files\n",
    "transcript_docs = []\n",
    "module_dirs = os.listdir(TRANSCRIPT_DIR)\n",
    "transcript_doc_processor = TranscriptDocProcessor(text_splitter_options=TEXT_SPLITTER_OPTIONS, return_dict=RETURN_DICT)\n",
    "\n",
    "for module_dir in module_dirs:\n",
    "    module_path = os.path.join(TRANSCRIPT_DIR, module_dir)\n",
    "    docs = transcript_doc_processor.process_module_transcripts(module_path)\n",
    "    for doc in docs:\n",
    "        doc.metadata['content_type'] = 'video_transcript'\n",
    "    transcript_docs.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_docs = html_content_docs + transcript_docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Embeddings and Vector DB Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=MODEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the text with contextual header for dense embedding. The added context will improve the representation of the embeddings. I don't modify the text directly in the document as it would complicate the indexing and deduplication step during the post-retrieval step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_contextual_header(doc):\n",
    "    source_metadata = doc.metadata\n",
    "    if source_metadata['content_type'] == 'video_transcript':\n",
    "        # Replace newlines with a single space and truncate to 1000 characters\n",
    "        video_desc = re.sub(r'\\n+', ' ', source_metadata['video_desc'][:1000])\n",
    "        return f\"Video transcript snippet from video with a description of: {video_desc.strip()}.\"\n",
    "        \n",
    "    elif source_metadata['content_type'] == 'html_content':\n",
    "        return (\n",
    "            f\"Content snippet of: {source_metadata['module_title']} - \"\n",
    "            f\"{source_metadata['subsection']}: {source_metadata['submodule_title']}.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_texts = []\n",
    "for doc in combined_docs:\n",
    "    doc.metadata['contextual_header'] = generate_contextual_header(doc)\n",
    "    contextual_texts.append(f\"{doc.metadata['contextual_header']}\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_vectors = embeddings.embed_documents(contextual_texts)\n",
    "# with open(\"artifact/emgt605/openai_dense_vectors.json\", \"w\") as f:\n",
    "#     json.dump(dense_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vectors = json.load(open(\"artifact/emgt605/openai_dense_vectors.json\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Azure Search Index with `SearchIndexClient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(client: SearchIndexClient,\n",
    "                index_name: str, embeddings_dim: int):\n",
    "    \n",
    "    vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "        )\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    fields = [\n",
    "        SimpleField(name=\"pk\", type=SearchFieldDataType.String, key=True, filterable=True),\n",
    "        SearchableField(name=\"text\", type=SearchFieldDataType.String),\n",
    "        SearchField(\n",
    "        name=\"dense_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=embeddings_dim,\n",
    "        vector_search_profile_name=\"myHnswProfile\",\n",
    "        ),\n",
    "        ComplexField(name=\"metadata\", fields=[\n",
    "            SimpleField(name=\"start_index\", type=SearchFieldDataType.Int32),\n",
    "            SimpleField(name=\"module_title\", type=SearchFieldDataType.String, filterable=True),\n",
    "            SimpleField(name=\"subsection\", type=SearchFieldDataType.String, filterable=True),\n",
    "            SimpleField(name=\"submodule_title\", type=SearchFieldDataType.String, filterable=True),\n",
    "            SimpleField(name=\"submodule_url\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"video_title\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"video_url\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"video_desc\", type=SearchFieldDataType.String),\n",
    "            SimpleField(name=\"content_type\", type=SearchFieldDataType.String, filterable=True),\n",
    "            SimpleField(name=\"contextual_header\", type=SearchFieldDataType.String)]),\n",
    "        SimpleField(name=\"index_metadata\", type=SearchFieldDataType.String),\n",
    "        ]\n",
    "    \n",
    "    cors_options = CorsOptions(allowed_origins=[\"*\"], max_age_in_seconds=60)\n",
    "    \n",
    "    semantic_config = SemanticConfiguration(\n",
    "        name=\"my-semantic-config\",\n",
    "        prioritized_fields=SemanticPrioritizedFields(\n",
    "            title_field=None, \n",
    "            keywords_fields=None,\n",
    "            content_fields=[SemanticField(field_name=\"text\")]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "    \n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        scoring_profiles=[],\n",
    "        cors_options=cors_options, \n",
    "        vector_search=vector_search,\n",
    "        semantic_search=semantic_search)\n",
    "\n",
    "    client.create_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = SearchIndexClient(AZURE_SEARCH_ENDPOINT, AzureKeyCredential(AZURE_SEARCH_KEY))\n",
    "embeddings_dim = len(dense_vectors[0])\n",
    "\n",
    "create_index(client, INDEX_NAME, embeddings_dim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Langchain documents to a dictionary with the required fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_doc_to_dict(doc):\n",
    "    doc_dict = doc.dict()\n",
    "    doc_dict['index_metadata'] = doc_dict['metadata'].pop('index_metadata', [])\n",
    "    doc_dict['index_metadata'] = json.dumps(doc_dict['index_metadata'])\n",
    "    doc_dict['text'] = doc_dict.pop('page_content', None)\n",
    "    doc_dict.pop('id', None)\n",
    "    doc_dict.pop('type', None)\n",
    "    doc_dict['pk'] = uuid.uuid4().hex\n",
    "    return doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marselo\\AppData\\Local\\Temp\\ipykernel_15396\\4040010649.py:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  doc_dict = doc.dict()\n"
     ]
    }
   ],
   "source": [
    "combined_dict = [convert_doc_to_dict(doc) for doc in combined_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(combined_dict):\n",
    "    doc['dense_vector'] = dense_vectors[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Azure Search Index with  `SearchClient`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "\n",
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=AzureKeyCredential(AZURE_SEARCH_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search_client.upload_documents(combined_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import HybridSearch\n",
    "from azure.search.documents.models import VectorizedQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=AzureKeyCredential(AZURE_SEARCH_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the difference between finance and economy?\" \n",
    "embedded_query = embeddings.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    search_fields=[\"text\"],\n",
    "    # max_text_recall_size indicates the number of results to return from the text search\n",
    "    hybrid_search=HybridSearch(max_text_recall_size=5),\n",
    "    # k_nearest_neighbors indicates the number of results to return from the vector search\n",
    "    vector_queries= [VectorizedQuery(vector=embedded_query, k_nearest_neighbors=5, fields=\"dense_vector\")],\n",
    "    # top indicates the number of results after reranking the vector and sparse results\n",
    "    top=5,\n",
    "    select=[\"pk\", \"text\", \"metadata\", \"index_metadata\"],\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"my-semantic-config\"\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(results)\n",
    "\n",
    "# convert index_metadata back as a list of dictionaries from a string\n",
    "for r in results:\n",
    "    r['index_metadata'] = json.loads(r['index_metadata'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "144bd6d3fc5519aff641c83bff45e33e7f2b2685b4cfe9cf21f9ad4099bb0e8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
