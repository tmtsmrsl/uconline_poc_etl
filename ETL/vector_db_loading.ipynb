{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to check the dependencies in the requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marselo\\OneDrive\\Documents\\GitHub\\uconline_poc\\env.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pymilvus.model.hybrid import BGEM3EmbeddingFunction\n",
    "from pymilvus.model.sparse.bm25 import BM25EmbeddingFunction\n",
    "from pymilvus import (\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    "    connections,\n",
    ")\n",
    "\n",
    "from ContentProcessor import ContentDocProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HTML to Split Documents Conversion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the CourseScraper to scrape the submodule HTML contents. If running from the project root directory, the command would look like this:\n",
    "```bash\n",
    "python ETL/CourseScraper.py --input_json course_materials/emgt605/module_urls.json --ouput_dir course_materials/emgt605/module_content\n",
    "```\n",
    "\n",
    "Then we will load the output JSON files from the `module_content` directory and convert the HTML content into documents (dict) with the text split into sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the directory containing the JSON files output of CourseScraper.py\n",
    "JSON_DIR = \"../course_materials/emgt605/module_content\"\n",
    "\n",
    "# The CSS elements to exclude when extracting text from the HTML content\n",
    "EXCLUDED_ELEMENTS_CSS='div.quiz-card__feedback, div.block-knowledge__retake-container, iframe, img, a'\n",
    "CHUNK_TOKEN_SIZE = 500\n",
    "CHUNK_TOKEN_OVERLAP = 50\n",
    "\n",
    "# We will run process all JSON files in the JSON_DIR and collect all the resulting Docments\n",
    "combined_docs = []\n",
    "json_files = [f for f in os.listdir(JSON_DIR) if f.endswith('.json')]\n",
    "processor = ContentDocProcessor(excluded_elements_css=EXCLUDED_ELEMENTS_CSS, chunk_token_size=CHUNK_TOKEN_SIZE, chunk_token_overlap=CHUNK_TOKEN_OVERLAP)\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(JSON_DIR, json_file)\n",
    "    docs = processor.run(json_path)\n",
    "    combined_docs.extend(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Embeddings and Vector DB Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the normal text for sparse embedding and text with contextual header for the dense embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contextual_headers(doc):\n",
    "    context = f\"Content snippet of: {doc['module_title']} - {doc['subsection']}: {doc['submodule_title']}\"\n",
    "    return context + \"\\n\" + doc['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_doc_texts = [doc['text'] for doc in combined_docs]\n",
    "\n",
    "dense_doc_texts = [add_contextual_headers(doc) for doc in combined_docs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the dense embedding model. Note that using GPU is highly recommended for this task as it will be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dense_embeddings = BGEM3EmbeddingFunction(use_fp16=False, device=DEVICE, return_dense=True, return_sparse=False)\n",
    "dense_dim = dense_embeddings.dim['dense']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the BM25 sparse embeddings and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARSE_EMBEDDINGS_PATH = \"../artifact/emgt605/sparse_embeddings.joblib\"\n",
    "\n",
    "sparse_embeddings = BM25EmbeddingFunction(corpus=sparse_doc_texts)\n",
    "\n",
    "folder_path = os.path.dirname(SPARSE_EMBEDDINGS_PATH)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "joblib.dump(sparse_embeddings, SPARSE_EMBEDDINGS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dense and sparse vectors for the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = sparse_embeddings.encode_documents(sparse_doc_texts)\n",
    "dense_vectors = dense_embeddings.encode_documents(dense_doc_texts)\n",
    "\n",
    "for i, doc in enumerate(combined_docs):\n",
    "    doc['sparse_vector'] = sparse_vectors[[i], :]\n",
    "    doc['dense_vector'] = dense_vectors['dense'][i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a connection to the Zilliz vector database and load the embeddings into the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the parameter to connect to the Zilliz vector database\n",
    "ZILLIZ_URI = os.getenv(\"ZILLIZ_URI\")\n",
    "ZILLIZ_USER = os.getenv(\"ZILLIZ_USER\")\n",
    "ZILLIZ_PASSWORD = os.getenv(\"ZILLIZ_PASSWORD\")\n",
    "COLLECTION_NAME = \"emgt_605_bge_bm25_500_50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(user=ZILLIZ_USER, password=ZILLIZ_PASSWORD, uri=ZILLIZ_URI)\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(\n",
    "        name=\"pk\", dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=100\n",
    "    ),\n",
    "    FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=8192),\n",
    "    FieldSchema(name=\"sparse_vector\", dtype=DataType.SPARSE_FLOAT_VECTOR),\n",
    "    FieldSchema(name=\"dense_vector\", dtype=DataType.FLOAT_VECTOR, dim=dense_dim),\n",
    "    FieldSchema(name=\"module_title\", dtype=DataType.VARCHAR, max_length=500),\n",
    "    FieldSchema(name=\"subsection\", dtype=DataType.VARCHAR, max_length=500),\n",
    "    FieldSchema(name=\"submodule_title\", dtype=DataType.VARCHAR, max_length=500),\n",
    "    FieldSchema(name=\"submodule_url\", dtype=DataType.VARCHAR, max_length=500),\n",
    "    FieldSchema(name=\"start_index\", dtype=DataType.INT32), \n",
    "    FieldSchema(name=\"data_block_ranges\", dtype=DataType.JSON), \n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields, \"Dense (BGE-M3) and Sparse (BM25) Embeddings for EMGT605 Course Content\")\n",
    "col = Collection(COLLECTION_NAME, schema)\n",
    "\n",
    "sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "dense_index = {\"index_type\": \"FLAT\", \"metric_type\": \"COSINE\"}\n",
    "col.create_index(\"sparse_vector\", sparse_index)\n",
    "col.create_index(\"dense_vector\", dense_index)\n",
    "\n",
    "col.insert(combined_docs)\n",
    "col.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieval Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the documents has been loaded correctly into the vector database. Note that we will initialize the retriever using the pymilvus SDK instead of Langchain because currently Langchain does not support the BM25 retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(user=ZILLIZ_USER, password=ZILLIZ_PASSWORD, uri=ZILLIZ_URI)\n",
    "col = Collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the core pillars for sustainability?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_query = dense_embeddings.encode_queries([query])['dense']\n",
    "dense_results = col.search(dense_query, anns_field=\"dense_vector\", limit=3, param={\"metric_type\": \"COSINE\"}, output_fields=['text'])\n",
    "# print(dense_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_query = sparse_embeddings.encode_queries([query])\n",
    "sparse_results = col.search(sparse_query, anns_field=\"sparse_vector\", limit=3, param={\"metric_type\": \"IP\"}, output_fields=['text'])\n",
    "# print(sparse_results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9502d0775d3b286aba2791f50951496b3067599c98afd76ac17979de40c4377"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
