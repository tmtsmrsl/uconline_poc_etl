{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to check the dependencies in the requirements.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_milvus.vectorstores import Milvus\n",
    "from langchain_milvus.utils.sparse import BM25SparseEmbedding\n",
    "from pymilvus import connections, Collection\n",
    "\n",
    "from ContentProcessor import ContentDocProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HTML to LangChain Document Conversion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the CourseScraper to scrape the submodule HTML contents. If running from the project root directory, the command would look like this:\n",
    "```bash\n",
    "python ETL/CourseScraper.py --input_json course_materials/emgt605/module_urls.json --ouput_dir course_materials/emgt605/module_content\n",
    "```\n",
    "\n",
    "Then we will load the output JSON files from the `module_content` directory and convert them into LangChain documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the directory containing the JSON files output of CourseScraper.py\n",
    "JSON_DIR = \"../course_materials/emgt605/module_content\"\n",
    "\n",
    "# The CSS elements to exclude when extracting text from the HTML content\n",
    "EXCLUDED_ELEMENTS_CSS='div.quiz-card__feedback, div.block-knowledge__retake-container, iframe, img, a'\n",
    "\n",
    "# We will run process all JSON files in the JSON_DIR and collect all the resulting Docments\n",
    "combined_docs = []\n",
    "json_files = [f for f in os.listdir(JSON_DIR) if f.endswith('.json')]\n",
    "processor = ContentDocProcessor(excluded_elements_css=EXCLUDED_ELEMENTS_CSS)\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(JSON_DIR, json_file)\n",
    "    docs = processor.run(json_path)\n",
    "    combined_docs.extend(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Embeddings and Vector DB Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the dense embedding model. Note that using GPU is highly recommended for this task as it will be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize GPU to load and infer the embedding model if available \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EMBEDDING_MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
    "\n",
    "model_kwargs = {\"device\": DEVICE, \"trust_remote_code\":True}\n",
    "dense_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME, model_kwargs=model_kwargs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the BM25 sparse embeddings and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marselo\\OneDrive\\Documents\\GitHub\\uconline_poc\\new.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sparse_embeddings.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPARSE_EMBEDDINGS_PATH = \"sparse_embeddings.joblib\"\n",
    "\n",
    "combined_texts = [doc.page_content for doc in combined_docs]\n",
    "sparse_embeddings = BM25SparseEmbedding(combined_texts)\n",
    "\n",
    "joblib.dump(sparse_embeddings, SPARSE_EMBEDDINGS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a connection to the Zilliz vector database and load the embeddings into the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the parameter to connect to the Zilliz vector database\n",
    "ZILLIZ_URI = os.getenv(\"ZILLIZ_URI\")\n",
    "ZILLIZ_USER = os.getenv(\"ZILLIZ_USER\")\n",
    "ZILLIZ_PASSWORD = os.getenv(\"ZILLIZ_PASSWORD\")\n",
    "COLLECTION_NAME = \"emgt_605_jina_hybrid\"\n",
    "\n",
    "# initialize the Milvus vector database using Langchain Python SDK\n",
    "vector_db = Milvus(\n",
    "    embedding_function=[dense_embeddings, sparse_embeddings],\n",
    "    vector_field=[\"dense_vectors\", \"sparse_vectors\"],\n",
    "    connection_args={\n",
    "        \"uri\": ZILLIZ_URI,\n",
    "        \"user\": ZILLIZ_USER,\n",
    "        \"password\": ZILLIZ_PASSWORD,\n",
    "        \"secure\": True},\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    auto_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the documents from step 1 to the vector database\n",
    "vector_db.add_documents(combined_docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieval Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the documents has been loaded correctly into the vector database. Note that we will initialize the retriever using the pymilvus SDK instead of Langchain because currently Langchain does not support the BM25 retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect(user=ZILLIZ_USER, password=ZILLIZ_PASSWORD, uri=ZILLIZ_URI)\n",
    "col = Collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the core pillars for sustainability?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_query = dense_embeddings.embed_query(query)\n",
    "dense_results = col.search([dense_query], anns_field=\"dense_vectors\", limit=3, param={\"metric_type\": \"L2\"}, output_fields=['text'])\n",
    "# print(dense_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_query = sparse_embeddings.embed_query(query)\n",
    "sparse_results = col.search([sparse_query], anns_field=\"sparse_vectors\", limit=3, param={\"metric_type\": \"IP\"}, output_fields=['text'])\n",
    "# print(sparse_results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2beb8962fb3b1b48ac06cfc8d19ae813ba32f84b9d281001b33fdb8a613e752"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
